{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install snowflake-connector-python\n",
    "!pip install tldextract\n",
    "!pip install py2neo"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.site.gs.com/simple\n",
      "Requirement already satisfied: snowflake-connector-python in /usr/local/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (1.15.1)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (3.17)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (1.26.14)\n",
      "Requirement already satisfied: cryptography<41.0.0,>=3.1.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (2022.12.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (23.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (22.0.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (2.1.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (2.6.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (2022.7.1)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (1.3.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /usr/local/lib/python3.8/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.8/site-packages (from cryptography<41.0.0,>=3.1.0->snowflake-connector-python) (1.16.0)\n",
      "\u001B[33mWARNING: You are using pip version 20.2; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.site.gs.com/simple\n",
      "Requirement already satisfied: tldextract in ./.local/lib/python3.8/site-packages (3.4.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.8/site-packages (from tldextract) (2.28.2)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.8/site-packages (from tldextract) (3.10.7)\n",
      "Requirement already satisfied: requests-file>=1.4 in ./.local/lib/python3.8/site-packages (from tldextract) (1.5.1)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.8/site-packages (from tldextract) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.1.0->tldextract) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.1.0->tldextract) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests>=2.1.0->tldextract) (2.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from requests-file>=1.4->tldextract) (1.16.0)\n",
      "\u001B[33mWARNING: You are using pip version 20.2; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.site.gs.com/simple\n",
      "Requirement already satisfied: py2neo in ./.local/lib/python3.8/site-packages (2021.2.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from py2neo) (23.0)\n",
      "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.8/site-packages (from py2neo) (2.14.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/site-packages (from py2neo) (1.26.14)\n",
      "Requirement already satisfied: pansi>=2020.7.3 in ./.local/lib/python3.8/site-packages (from py2neo) (2020.7.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/site-packages (from py2neo) (2022.12.7)\n",
      "Requirement already satisfied: monotonic in ./.local/lib/python3.8/site-packages (from py2neo) (1.6)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.8/site-packages (from py2neo) (1.16.0)\n",
      "Requirement already satisfied: interchange~=2021.0.4 in ./.local/lib/python3.8/site-packages (from py2neo) (2021.0.4)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.8/site-packages (from interchange~=2021.0.4->py2neo) (2022.7.1)\n",
      "\u001B[33mWARNING: You are using pip version 20.2; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001B[0m\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "RyOaINR792wfytSX8yCREb",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "LXlZ1NeQDTK0mx93kQDFEG"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snowflake.connector\n",
    "import os\n",
    "from py2neo import Graph\n",
    "from py2neo.bulk import merge_nodes, create_relationships, merge_relationships\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#[Environment Configs]\n",
    "client_id = \"d0afa05e7ab642acb0497f018b601b86\"\n",
    "client_secret = \"ikdU3eOtXRmMR9oWlEnP0W0jAVZYNMBF2FUwsuwtHkZ37Oh4IZZkso3tFdsbfdmO\"  \n",
    "os.environ[\"HTTP_PROXY\"] = \"http://d161560-001.dc.gs.com:8899\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://d161560-001.dc.gs.com:8899\"\n",
    "\n",
    "#[Credentials]\n",
    "host = \"xplore.graph-x.site.gs.com\"\n",
    "port = \"7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"xplorer\"\n",
    "graph = Graph(host=host, port=port, auth=(username, password))\n",
    "BATCHES = 100\n"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "bDRowly7Jij4KCmUB52L9E",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "sx94cb9xUkhcte19ETSAF4"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Libraries & Shared Code"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "F25Mzdwfky23ceZLniVqy5",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "biDlE0bNXIAuEpUELHXGcJ"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_oauth_tokens(client_id: str, client_secret: str):\n",
    "    _IDFS_URL = \"https://idfs.gs.com/as/token.oauth2\"\n",
    "    response = requests.post(\n",
    "        url = _IDFS_URL,\n",
    "        params = {\"access_token_manager_id\": \"JwtSnowflake\"},  # This must be set to JwtSnowflake to generate Snowflake-compatible OAuth Token\n",
    "        data = {\"grant_type\": \"client_credentials\", \"scope\": \"SESSION:ROLE-ANY\"},\n",
    "        auth = (client_id, client_secret),\n",
    "    )\n",
    "    response = response.json()\n",
    "    if \"access_token\" not in response.keys():\n",
    "        raise PermissionError(f\"Not authorized to access OAuth Tokens: {response}\")\n",
    "    return response[\"access_token\"]\n",
    "  \n",
    "def connect_snowflake(user: str, database: str, token: str) -> snowflake.connector.cursor:\n",
    "    \"\"\"Connect to Snowflake and return an authorized cursor. Below uses Catalyst connections\n",
    "   \n",
    "    :param user: Client ID from OAuth2 Authentication\n",
    "    :param database: Name of database to connect to\n",
    "    :param token: Generated OAuth Token. Please either generate and save to a tmp file in a separate thread OR use subprocess module to call the underlying subsystem and capture the output\n",
    "    :return: Snowflake Cursor\n",
    "    \"\"\"\n",
    "    snow_connector = snowflake.connector.connect(\n",
    "        user=user,\n",
    "        authenticator=\"oauth\",\n",
    "        account=\"sfamdprvtawseast1d01.goldman.us-east-1.aws.privatelink\",\n",
    "        role=\"AMD_CATALYST_DATA_RW\",\n",
    "        warehouse=\"AMD_CATALYST_RW\",\n",
    "        database=database,\n",
    "        ocsp_fail_open=False,\n",
    "        token=token,\n",
    "    )\n",
    "    cursor = snow_connector.cursor()\n",
    "    return cursor\n",
    " \n",
    "def disconnect(cursor: snowflake.connector.cursor) -> None:\n",
    "    try:\n",
    "        cursor.close()\n",
    "    except:\n",
    "        raise Exception(\"Failed to close cursor\")   \n",
    "        \n",
    "oauth_token = get_oauth_tokens(client_id, client_secret)\n",
    "cursor = connect_snowflake(client_id, \"AMD_CATALYST_DB\", oauth_token)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "KX99fhCoDsANzQ3NvJqjl1",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "CChejMMVamyPr16weP6Oq8"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SourceScrub Person\n",
    "### Step 3: Creating Nodes"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "v9axPSJzFSq40h7GDAXWFf",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "8NwKibJn7nAgQMJUzPCbfS"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_persons_df = cursor.execute('SELECT ID, FIRSTNAME, LASTNAME, LINKEDIN, CITY, STATE, COUNTRY FROM L1.SOURCESCRUB_PERSON').fetch_pandas_all()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "oxVbFASoB745ig8QR84cTL",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "V1d1lRZPImxSKcD9c2O7nc"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display(sourcescrub_persons_df.head(5))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FIRSTNAME</th>\n",
       "      <th>LASTNAME</th>\n",
       "      <th>LINKEDIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2874625</td>\n",
       "      <td>Craig</td>\n",
       "      <td>Gress</td>\n",
       "      <td>https://www.linkedin.com/in/craiggress</td>\n",
       "      <td>Chinle</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2874624</td>\n",
       "      <td>Eduardo</td>\n",
       "      <td>Resende</td>\n",
       "      <td>https://www.linkedin.com/in/edresende</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2874623</td>\n",
       "      <td>Miguel</td>\n",
       "      <td>Angel</td>\n",
       "      <td>None</td>\n",
       "      <td>Deba</td>\n",
       "      <td>Euskal Autonomia Erkidegoa</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2874622</td>\n",
       "      <td>Brendan</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>https://www.linkedin.com/in/brendanbateman</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2874621</td>\n",
       "      <td>Alena</td>\n",
       "      <td>Bennett</td>\n",
       "      <td>https://www.linkedin.com/in/alenabennett</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "        ID FIRSTNAME LASTNAME                                    LINKEDIN  \\\n",
       "0  2874625     Craig    Gress      https://www.linkedin.com/in/craiggress   \n",
       "1  2874624   Eduardo  Resende       https://www.linkedin.com/in/edresende   \n",
       "2  2874623    Miguel    Angel                                        None   \n",
       "3  2874622   Brendan  Bateman  https://www.linkedin.com/in/brendanbateman   \n",
       "4  2874621     Alena  Bennett    https://www.linkedin.com/in/alenabennett   \n",
       "\n",
       "        CITY                       STATE        COUNTRY  \n",
       "0     Chinle                     Arizona  United States  \n",
       "1  Sao Paulo                   Sao Paulo         Brazil  \n",
       "2       Deba  Euskal Autonomia Erkidegoa          Spain  \n",
       "3     Sydney    State of New South Wales      Australia  \n",
       "4     Sydney    State of New South Wales      Australia  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "NDvdX1yZZJnPVMvmtP2R9u",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "nzcr9gq4IH3vZ3jWILMrhM"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "display(sourcescrub_persons_df.head(5))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LINKEDIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2874625</td>\n",
       "      <td>https://www.linkedin.com/in/craiggress</td>\n",
       "      <td>Chinle</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>United States</td>\n",
       "      <td>Craig Gress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2874624</td>\n",
       "      <td>https://www.linkedin.com/in/edresende</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Eduardo Resende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2874623</td>\n",
       "      <td>None</td>\n",
       "      <td>Deba</td>\n",
       "      <td>Euskal Autonomia Erkidegoa</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Miguel Angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2874622</td>\n",
       "      <td>https://www.linkedin.com/in/brendanbateman</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Brendan Bateman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2874621</td>\n",
       "      <td>https://www.linkedin.com/in/alenabennett</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Alena Bennett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "        ID                                    LINKEDIN       CITY  \\\n",
       "0  2874625      https://www.linkedin.com/in/craiggress     Chinle   \n",
       "1  2874624       https://www.linkedin.com/in/edresende  Sao Paulo   \n",
       "2  2874623                                        None       Deba   \n",
       "3  2874622  https://www.linkedin.com/in/brendanbateman     Sydney   \n",
       "4  2874621    https://www.linkedin.com/in/alenabennett     Sydney   \n",
       "\n",
       "                        STATE        COUNTRY             NAME  \n",
       "0                     Arizona  United States      Craig Gress  \n",
       "1                   Sao Paulo         Brazil  Eduardo Resende  \n",
       "2  Euskal Autonomia Erkidegoa          Spain     Miguel Angel  \n",
       "3    State of New South Wales      Australia  Brendan Bateman  \n",
       "4    State of New South Wales      Australia    Alena Bennett  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "7l8iugQ4QMPxt2faM0Cjz5",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "KXwIvq45IBBRjVUzjS90Bf"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sourcescrub_persons_df['LINKEDIN'] = sourcescrub_persons_df['LINKEDIN'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ingesting Common SourceScrub Identifiers into Graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "444968\n",
    "444968"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dividing the DataFrame into smaller chunks for ingestion\n",
    "sourcescrub_persons_df_linkedin = np.array_split(sourcescrub_persons_df[sourcescrub_persons_df['LINKEDIN'].notna()][['LINKEDIN']].rename(columns={'LINKEDIN': 'URL'}).to_dict('records'), BATCHES)\n",
    "\n",
    "# Creating nodes for LinkedIn identifiers\n",
    "for chunk_df in sourcescrub_persons_df_linkedin:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"LinkedInURL\"), \"URL\"),\n",
    "    )\n",
    "\n",
    "# Creating nodes for Sourcescrub Persons\n",
    "sourcescrub_persons = np.array_split([{k:v for k, v in x.items() if pd.notnull(v)} for x in sourcescrub_persons_df.to_dict('records')], BATCHES)\n",
    "for chunk_df in sourcescrub_persons:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "smHRKv8A0u9BA16ELkQpMe",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "Gz8cMbVeF4VFv0RQeSSyE8"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_persons_df.head(5)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_ID</th>\n",
       "      <th>LINKEDIN</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcescrub-2874625</td>\n",
       "      <td>linkedin.com/in/craiggress</td>\n",
       "      <td>Chinle</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>United States</td>\n",
       "      <td>Craig Gress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcescrub-2874624</td>\n",
       "      <td>linkedin.com/in/edresende</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Eduardo Resende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcescrub-2874623</td>\n",
       "      <td></td>\n",
       "      <td>Deba</td>\n",
       "      <td>Euskal Autonomia Erkidegoa</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Miguel Angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcescrub-2874622</td>\n",
       "      <td>linkedin.com/in/brendanbateman</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Brendan Bateman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sourcescrub-2874621</td>\n",
       "      <td>linkedin.com/in/alenabennett</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Alena Bennett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             SOURCE_ID                        LINKEDIN       CITY  \\\n",
       "0  sourcescrub-2874625      linkedin.com/in/craiggress     Chinle   \n",
       "1  sourcescrub-2874624       linkedin.com/in/edresende  Sao Paulo   \n",
       "2  sourcescrub-2874623                                       Deba   \n",
       "3  sourcescrub-2874622  linkedin.com/in/brendanbateman     Sydney   \n",
       "4  sourcescrub-2874621    linkedin.com/in/alenabennett     Sydney   \n",
       "\n",
       "                        STATE        COUNTRY             NAME  \n",
       "0                     Arizona  United States      Craig Gress  \n",
       "1                   Sao Paulo         Brazil  Eduardo Resende  \n",
       "2  Euskal Autonomia Erkidegoa          Spain     Miguel Angel  \n",
       "3    State of New South Wales      Australia  Brendan Bateman  \n",
       "4    State of New South Wales      Australia    Alena Bennett  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "poYp6ssHQ9fxs8RkagDup5",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "KlX1PJTSfq7XP6w5QMQc2D"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ingesting Common SourceScrub Identifiers into Graph"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "szEUIhgrisLsXfK0Uo3lVP",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "pjbAuBPpBnGmkziRTPPw27"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_persons_df_linkedin = np.array_split(sourcescrub_persons_df[sourcescrub_persons_df['LINKEDIN'].isna() == False][['LINKEDIN']].rename(columns={'LINKEDIN': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in sourcescrub_persons_df_linkedin:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"LinkedInURL\"), \"URL\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "HxVT2Aa0NMYJagCuwUW3si",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "DjRzLlMy9pqa2GL2R4gMGc"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_persons =np.array_split([{k:v for k, v in x.items() if v == v} for x in sourcescrub_persons_df.to_dict('records')], BATCHES)\n",
    "for chunk_df in sourcescrub_persons:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "fKkjP0N1WLqbb2tTiizYqr",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "VaAuUvdiPt8RT4JH90wHZA"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_identifier_relationships = sourcescrub_persons_df.loc[sourcescrub_persons_df['LINKEDIN'] != np.nan][['SOURCE_ID', 'LINKEDIN']]\n",
    "sourcescrub_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_identifier_relationships))\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "for chunk_df in df_list:\n",
    "        merge_relationships(\n",
    "            graph.auto(),\n",
    "            chunk_df.values.tolist(),\n",
    "            merge_key=\"LINKED_TO\",\n",
    "            start_node_key=((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "            end_node_key=((\"URLIdentifier\", \"LinkedInURL\"), \"URL\"),\n",
    "            keys=[\"WEIGHT\"]\n",
    "        )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "TGv41SDrX6Prhw7LbRBk7Q",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "G8qFgE0TH9oNspv36ObIQX"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Person to Company"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "kVQ6JwXAE3asIucLaU70vT",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "JHMwNAZEzhBPFa7tc3Lens"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_p2c_df = cursor.execute('SELECT PERSONID ,COMPANYID, STARTDATE, ENDDATE FROM L1.SOURCESCRUB_PERSONTOCOMPANY').fetch_pandas_all()\n",
    "sourcescrub_p2c_df.head()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "NameError: name 'cursor' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 1 in <module>",
      "NameError: name 'cursor' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "PwOZ0zIlPbJHOPYymxoCAp",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "qTFa18DszyzNvKBnuREhWt"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_p2c_df.rename(columns={'PERSONID': 'PERSON_ID', 'COMPANYID': 'COMPANY_ID', 'STARTDATE': 'START_DATE', 'ENDDATE': 'END_DATE'}, inplace=True)\n",
    "sourcescrub_p2c_df.START_DATE = sourcescrub_p2c_df.START_DATE.fillna(0).astype('str').replace('0', np.nan)\n",
    "sourcescrub_p2c_df.END_DATE = sourcescrub_p2c_df.END_DATE.fillna(0).astype('str').replace('0', np.nan)\n",
    "sourcescrub_p2c_df.head()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "bpdqOZH5uOPjjesuLQRJBS",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "TAhZf2zUnjdwAKicpENciY"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_curr_p2c_df = sourcescrub_p2c_df[sourcescrub_p2c_df['END_DATE'] .isna() == True]\n",
    "print(sourcescrub_curr_p2c_df.shape)\n",
    "\n",
    "\n",
    "sourcescrub_prev_p2c_df = sourcescrub_p2c_df[sourcescrub_p2c_df['END_DATE'].isna() == False]\n",
    "print(sourcescrub_prev_p2c_df.shape)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "GkTmuy0Y6QoYMnWUtSCnKC",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "OOHXTgSz1UlUU9YzWBQ2h2"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sourcescrub_identifier_relationships = sourcescrub_prev_p2c_df.loc[sourcescrub_prev_p2c_df['LINKEDIN'] != np.nan][['SOURCE_ID', 'LINKEDIN']]\n",
    "sourcescrub_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_identifier_relationships))\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"PREVIOUST_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "        )\n",
    "    "
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "HopRI59LwxSnA2sywZNQ5Y",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter for rows where CURRENT is True\n",
    "sourcescrub_identifier_relationships = sourcescrub_curr_p2c_df.loc[sourcescrub_curr_p2c_df['LINKEDIN'] != np.nan][['SOURCE_ID', 'LINKEDIN']]\n",
    "sourcescrub_p2c_current_relationships = sourcescrub_curr_p2c_df[['PERSON_ID', 'COMPANY_ID']]\n",
    "sourcescrub_p2c_current_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_p2c_current_relationships))\n",
    "df_list = np.array_split(sourcescrub_p2c_current_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"CURRENT_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "yL1aa65gNSWS8jwCfvfBLN",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 4: Creating Relationships\n",
    "# Creating relationships between SourceScrub persons and their LinkedIn URLs\n",
    "sourcescrub_identifier_relationships = sourcescrub_persons_df[sourcescrub_persons_df['LINKEDIN'].notna()][['SOURCE_ID', 'LINKEDIN']].copy()\n",
    "sourcescrub_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_identifier_relationships))\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"LINKED_TO\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "        end_node_key=((\"URLIdentifier\", \"LinkedInURL\"), \"LINKEDIN\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )\n",
    "\n",
    "# Step 5: Mapping Identifiers\n",
    "# Preparing relationships between persons and companies\n",
    "sourcescrub_p2c_df = cursor.execute('SELECT PERSONID ,COMPANYID, STARTDATE, ENDDATE FROM L1.SOURCESCRUB_PERSONTOCOMPANY').fetch_pandas_all()\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Mapping Identifiers\n",
    "# Preparing relationships between persons and companies\n",
    "sourcescrub_p2c_df.rename(columns={'PERSONID': 'PERSON_ID', 'COMPANYID': 'COMPANY_ID', 'STARTDATE': 'START_DATE', 'ENDDATE': 'END_DATE'}, inplace=True)\n",
    "\n",
    "# Creating relationships for previous employment\n",
    "sourcescrub_prev_p2c_df = sourcescrub_p2c_df[sourcescrub_p2c_df.END_DATE.notna()]\n",
    "df_list = np.array_split(sourcescrub_prev_p2c_df[['PERSON_ID', 'COMPANY_ID']], BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"PREVIOUS_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[]\n",
    "    )\n",
    "\n",
    "# Creating relationships for current employment\n",
    "sourcescrub_curr_p2c_df = sourcescrub_p2c_df[sourcescrub_p2c_df.END_DATE.isna()]\n",
    "df_list = np.array_split(sourcescrub_curr_p2c_df[['\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Crunchbase Persons"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "zuvcvM6T3l1TUk0zKLFDpi",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "gCeoNr1sJ0DWPaeJdGL7yc"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "6oFhGRiuVl26fmmY2UwjZT",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons_df = cursor.execute('SELECT UUID, \"CB URL\", NAME, \"TWITTER\", \"FACEBOOK\", \"LINKEDIN URL\", CITY, COUNTRY_CODE FROM L1.CRUNCHBASE_PEOPLE').fetch_pandas_all()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "YKNt754PLYAjbhw00eAlnj",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "JmF6iqQ5EyxPP6kJcMozlX"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons_df['UUID'] = 'crunchbase-' + crunchbase_persons_df['UUID'].astype(str)\n",
    "crunchbase_persons_df.rename(columns={'UUID': 'SOURCE_ID', 'CB URL': 'CRUNCHBASE', 'LINKEDIN URL': 'LINKEDIN'}, inplace=True)\n",
    "display(crunchbase_persons_df.head(5))"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "JCqX0G6jLHssKiTg2RsHUS",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "9p8A8l8gzQp7m9HU5HPTBl"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons_df['SOURCE_ID'] = 'sourcescrub-' + crunchbase_persons_df['SOURCE_ID']\n",
    "\n",
    "crunchbase_persons_df['LINKEDIN'] = crunchbase_persons_df['LINKEDIN'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_persons_df['TWITTER'] = crunchbase_persons_df['TWITTER'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_persons_df['FACEBOOK'] = crunchbase_persons_df['FACEBOOK'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_persons_df['CRUNCHBASE'] = crunchbase_persons_df['CRUNCHBASE'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "\n",
    "#sourcescrub_organizations_df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "mw4wY007PUjUJpUoTHYr1N",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "9N0q5HAoJAjVy47BRWTD57"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons_df.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>LINKEDIN</th>\n",
       "      <th>TWITTER</th>\n",
       "      <th>FACEBOOK</th>\n",
       "      <th>CRUNCHBASE</th>\n",
       "      <th>TIME_OF_FOUNDING</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>SPECIALTIES</th>\n",
       "      <th>TOTAL_AMOUNT_INVESTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcescrub-284125</td>\n",
       "      <td>Titanium Partners, LLC</td>\n",
       "      <td>titaniumpartnersllc.com</td>\n",
       "      <td>linkedin.com/company/titanium-partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>executive search, operations &amp; supply chain, t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcescrub-284124</td>\n",
       "      <td>Domtec International, LLC</td>\n",
       "      <td>domtec.com</td>\n",
       "      <td>linkedin.com/company/domtec-international</td>\n",
       "      <td>twitter.com/domtecint</td>\n",
       "      <td>facebook.com/domtecinternational</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Idaho Falls</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>United States</td>\n",
       "      <td>monolithic concrete bulk storage domes, thin-s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcescrub-284123</td>\n",
       "      <td>All Mountain Technologies, LLC</td>\n",
       "      <td>allmtntech.com</td>\n",
       "      <td>linkedin.com/company/all-mountain-technologies...</td>\n",
       "      <td>twitter.com/allmtntech</td>\n",
       "      <td>facebook.com/allmtntech</td>\n",
       "      <td>crunchbase.com/organization/all-mountain-techn...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>United States</td>\n",
       "      <td>it and network managed services, wireless netw...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcescrub-284122</td>\n",
       "      <td>Value Store It Self Storage</td>\n",
       "      <td>valuestoreit.com</td>\n",
       "      <td>linkedin.com/company/value-store-it</td>\n",
       "      <td>twitter.com/valuestoreit</td>\n",
       "      <td>facebook.com/valuestoreit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States</td>\n",
       "      <td>self storage, public storage, rv storage, auto...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sourcescrub-284121</td>\n",
       "      <td>Simsolid Corp.</td>\n",
       "      <td>altairhyperworks.com</td>\n",
       "      <td>linkedin.com/company/6440741</td>\n",
       "      <td>twitter.com/simsolid</td>\n",
       "      <td>facebook.com/simsolid.corporation</td>\n",
       "      <td>crunchbase.com/organization/simsolid</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Orange</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>structural simulation software, it software, c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            SOURCE_ID                            NAME  \\\n",
       "0  sourcescrub-284125          Titanium Partners, LLC   \n",
       "1  sourcescrub-284124       Domtec International, LLC   \n",
       "2  sourcescrub-284123  All Mountain Technologies, LLC   \n",
       "3  sourcescrub-284122     Value Store It Self Storage   \n",
       "4  sourcescrub-284121                  Simsolid Corp.   \n",
       "\n",
       "                    DOMAIN                                           LINKEDIN  \\\n",
       "0  titaniumpartnersllc.com             linkedin.com/company/titanium-partners   \n",
       "1               domtec.com          linkedin.com/company/domtec-international   \n",
       "2           allmtntech.com  linkedin.com/company/all-mountain-technologies...   \n",
       "3         valuestoreit.com                linkedin.com/company/value-store-it   \n",
       "4     altairhyperworks.com                       linkedin.com/company/6440741   \n",
       "\n",
       "                    TWITTER                           FACEBOOK  \\\n",
       "0                       NaN                                NaN   \n",
       "1     twitter.com/domtecint   facebook.com/domtecinternational   \n",
       "2    twitter.com/allmtntech            facebook.com/allmtntech   \n",
       "3  twitter.com/valuestoreit          facebook.com/valuestoreit   \n",
       "4      twitter.com/simsolid  facebook.com/simsolid.corporation   \n",
       "\n",
       "                                          CRUNCHBASE  TIME_OF_FOUNDING  \\\n",
       "0                                                NaN            2012.0   \n",
       "1                                                NaN            1995.0   \n",
       "2  crunchbase.com/organization/all-mountain-techn...            2003.0   \n",
       "3                                                NaN            2001.0   \n",
       "4               crunchbase.com/organization/simsolid            2015.0   \n",
       "\n",
       "          CITY                     STATE        COUNTRY  \\\n",
       "0       Sydney  State of New South Wales      Australia   \n",
       "1  Idaho Falls                     Idaho  United States   \n",
       "2      Edwards                  Colorado  United States   \n",
       "3        Miami                   Florida  United States   \n",
       "4       Orange                California  United States   \n",
       "\n",
       "                                         SPECIALTIES  TOTAL_AMOUNT_INVESTED  \n",
       "0  executive search, operations & supply chain, t...                    NaN  \n",
       "1  monolithic concrete bulk storage domes, thin-s...                    NaN  \n",
       "2  it and network managed services, wireless netw...                    NaN  \n",
       "3  self storage, public storage, rv storage, auto...                    NaN  \n",
       "4  structural simulation software, it software, c...                    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "7Z9chtYfFF0S2Ur52Mw6TB",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "PUguPOEwdeov3ooqLu25mw"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ingesting Common CB Identifiers into Graph"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "fNYwBxc38mAAaKRDHAGH3V",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "dt6akrXDGJ7FxI1RaHZiWY"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons_df_linkedin = np.array_split(crunchbase_persons_df[crunchbase_persons_df['LINKEDIN'].isna() == False][['LINKEDIN']].rename(columns={'LINKEDIN': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_persons_df_linkedin:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"LinkedInURL\"), \"URL\"),\n",
    "    )\n",
    "    \n",
    "crunchbase_persons_df_df_twitter = np.array_split(crunchbase_persons_df[crunchbase_persons_df['TWITTER'].isna() == False][['TWITTER']].rename(columns={'TWITTER': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_persons_df_df_twitter:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"TwitterURL\"), \"URL\"),\n",
    "    )\n",
    "\n",
    "crunchbase_persons_df_facebook =  np.array_split(crunchbase_persons_df[crunchbase_persons_df['FACEBOOK'].isna() == False][['FACEBOOK']].rename(columns={'FACEBOOK': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_persons_df_facebook:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"FacebookURL\"), \"URL\"),\n",
    "    )\n",
    "    \n",
    "crunchbase_persons_df_crunchbase =  np.array_split(crunchbase_persons_df[crunchbase_persons_df['CRUNCHBASE'].isna() == False][['CRUNCHBASE']].rename(columns={'CRUNCHBASE': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_persons_df_crunchbase:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"CrunchbaseURL\"), \"URL\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "6QlkN4l4039hmLRXiOq6nl",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "ayTVqtsljnOr9Qk7YoUy0k"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ingesting SourceScrub Companies into the Graph"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "DM162PjTwOp1YzvhY8OGAa",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "nOkY0tmaNT8ffM9sIHF1M8"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_persons = np.array_split([{k:v for k, v in x.items() if v == v} for x in crunchbase_persons_df.to_dict('records')], BATCHES)\n",
    "for chunk_df in crunchbase_persons:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"Person\", \"CrunchbasePerson\"), \"SOURCE_ID\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "lDok1atMf2SfLpOEhHtRfb",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "vUqNDaEKcHsgJN1wJHZgTX"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for identifier in ['LINKEDIN', 'TWITTER', 'FACEBOOK', 'CRUNCHBASE']:\n",
    "    cb_identifier_relationships = crunchbase_persons_df.loc[crunchbase_persons_df[identifier] != np.nan][['SOURCE_ID', identifier]]\n",
    "    cb_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(cb_identifier_relationships))\n",
    "\n",
    "    df_list = np.array_split(cb_identifier_relationships, BATCHES)\n",
    "    for chunk_df in df_list:\n",
    "        merge_relationships(\n",
    "            graph.auto(),\n",
    "            chunk_df.values.tolist(),\n",
    "            merge_key=\"LINKED_TO\",\n",
    "            start_node_key=(\"PERSON\", \"SOURCE_ID\"),\n",
    "            end_node_key=(\"URLIdentifier\", \"URL\"),\n",
    "            keys=[\"WEIGHT\"],\n",
    "        )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "3NZAJWzQG0i2J2aqHSOcjg",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "2k3SZ8K4Via8xnhoMErxGt"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "iSuN9dRqmPUaNOt5b5vzkR",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "rUuoNM2H60XCYyg5VhccRZ"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CrunchBase"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "HbH9sHVGvMJyxVYxO3Nf5Y",
     "type": "MD",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "IjklOPqGyju9jqSZkjAHnJ"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_organizations_df = cursor.execute('SELECT CRUNCHBASE_ORGANIZATION_UUID, ORGANIZATION_CITY, FACEBOOK_URL, DOMAIN, TWITTER_URL, FUNDING_ROUND_TYPE, FOUNDED_ON, EMPLOYEE_COUNT, CRUNCHBASE_GROUPS, ORGANIZATION_STATE_CODE, ORGANIZATION_NAME, LINKEDIN_URL, ORGANIZATION_COUNTRY_CODE, CRUNCHBASE_URL FROM L2_NEW.GRAPH_CRUNCHBASE_ORGANIZATIONS WHERE DOMAIN IS NOT NULL OR TWITTER_URL IS NOT NULL OR FACEBOOK_URL IS NOT NULL OR LINKEDIN_URL IS NOT NULL OR CRUNCHBASE_URL IS NOT NULL').fetch_pandas_all()\n",
    "crunchbase_organizations_df.rename(columns={\n",
    "    'CRUNCHBASE_ORGANIZATION_UUID': 'SOURCE_ID', \n",
    "    'TWITTER_URL': 'TWITTER', \n",
    "    'FACEBOOK_URL': 'FACEBOOK',\n",
    "    'LINKEDIN_URL': 'LINKEDIN',\n",
    "    'CRUNCHBASE_URL': 'CRUNCHBASE', \n",
    "    'FOUNDED_ON': 'TIME_OF_FOUNDING',\n",
    "    'ORGANIZATION_CITY': 'CITY',\n",
    "    'ORGANIZATION_STATE_CODE': 'STATE',\n",
    "    'ORGANIZATION_COUNTRY_CODE': 'COUNTRY', \n",
    "    'ORGANIZATION_NAME': 'NAME', \n",
    "    'LINKEDIN_URL': 'LINKEDIN'\n",
    "}, inplace=True)\n",
    "\n",
    "crunchbase_organizations_df.replace({None: ''}, inplace=True)\n",
    "\n",
    "crunchbase_organizations_df['LINKEDIN'] = crunchbase_organizations_df['LINKEDIN'].apply(lambda x: (str(urlparse(x.replace('[', '').replace(']', '')).netloc or '') + str(urlparse(x.replace('[', '').replace(']', '')).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_organizations_df['TWITTER'] = crunchbase_organizations_df['TWITTER'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_organizations_df['FACEBOOK'] = crunchbase_organizations_df['FACEBOOK'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "crunchbase_organizations_df['CRUNCHBASE'] = crunchbase_organizations_df['CRUNCHBASE'].apply(lambda x: (str(urlparse(x).netloc or '') + str(urlparse(x).path or '')).lstrip('www.').strip('/'))\n",
    "\n",
    "crunchbase_organizations_df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "display(crunchbase_organizations_df.head())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_ID</th>\n",
       "      <th>CITY</th>\n",
       "      <th>FACEBOOK</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>TWITTER</th>\n",
       "      <th>FUNDING_ROUND_TYPE</th>\n",
       "      <th>TIME_OF_FOUNDING</th>\n",
       "      <th>EMPLOYEE_COUNT</th>\n",
       "      <th>CRUNCHBASE_GROUPS</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LINKEDIN</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>CRUNCHBASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crunchbase-b883e57f-5a42-4cce-81f3-b70ad9482052</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>infinity.xyz</td>\n",
       "      <td>twitter.com/infinitydotxyz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Financial Services,Lending and Investments,Pay...</td>\n",
       "      <td>NY</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>crunchbase.com/organization/infinity-2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crunchbase-57eeadb3-5173-4fd9-a9f8-dec1ad472417</td>\n",
       "      <td>New York</td>\n",
       "      <td>facebook.com/pages/category/Insurance-company/...</td>\n",
       "      <td>skyviewagency.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-10</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>NY</td>\n",
       "      <td>SkyView Agency</td>\n",
       "      <td>linkedin.com/company/skyview-agency</td>\n",
       "      <td>USA</td>\n",
       "      <td>crunchbase.com/organization/skyview-agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crunchbase-f81e2ff9-6a87-4629-8a7e-230855a0dd30</td>\n",
       "      <td>Toshima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>muio.co.jp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991-02-01</td>\n",
       "      <td>11-50</td>\n",
       "      <td>Hardware,Information Technology,Internet Servi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muio Creative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JPN</td>\n",
       "      <td>crunchbase.com/organization/muio-creative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crunchbase-ebff3a2b-1b34-4bc8-8b46-5640352c99c0</td>\n",
       "      <td>Suva</td>\n",
       "      <td>facebook.com/vititalk</td>\n",
       "      <td>vititalk.com</td>\n",
       "      <td>twitter.com/viti_talk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Hardware,Messaging and Telecommunications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Viti Talk Telecommunications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FJI</td>\n",
       "      <td>crunchbase.com/organization/viti-talk-telecomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crunchbase-2774d086-6884-4d8b-9968-58181ed4e104</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>membershipcards.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>11-50</td>\n",
       "      <td>Content and Publishing,Design,Media and Entert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Membership Cards Only</td>\n",
       "      <td>linkedin.com/company/membership-cards-only-llc</td>\n",
       "      <td>AUT</td>\n",
       "      <td>crunchbase.com/organization/membership-cards-only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                         SOURCE_ID      CITY  \\\n",
       "0  crunchbase-b883e57f-5a42-4cce-81f3-b70ad9482052  New York   \n",
       "1  crunchbase-57eeadb3-5173-4fd9-a9f8-dec1ad472417  New York   \n",
       "2  crunchbase-f81e2ff9-6a87-4629-8a7e-230855a0dd30   Toshima   \n",
       "3  crunchbase-ebff3a2b-1b34-4bc8-8b46-5640352c99c0      Suva   \n",
       "4  crunchbase-2774d086-6884-4d8b-9968-58181ed4e104    Vienna   \n",
       "\n",
       "                                            FACEBOOK               DOMAIN  \\\n",
       "0                                                NaN         infinity.xyz   \n",
       "1  facebook.com/pages/category/Insurance-company/...    skyviewagency.com   \n",
       "2                                                NaN           muio.co.jp   \n",
       "3                              facebook.com/vititalk         vititalk.com   \n",
       "4                                                NaN  membershipcards.com   \n",
       "\n",
       "                      TWITTER FUNDING_ROUND_TYPE TIME_OF_FOUNDING  \\\n",
       "0  twitter.com/infinitydotxyz                NaN              NaN   \n",
       "1                         NaN                NaN              NaN   \n",
       "2                         NaN                NaN       1991-02-01   \n",
       "3       twitter.com/viti_talk                NaN              NaN   \n",
       "4                         NaN                NaN       1995-01-01   \n",
       "\n",
       "  EMPLOYEE_COUNT                                  CRUNCHBASE_GROUPS STATE  \\\n",
       "0        unknown  Financial Services,Lending and Investments,Pay...    NY   \n",
       "1           1-10                                 Financial Services    NY   \n",
       "2          11-50  Hardware,Information Technology,Internet Servi...   NaN   \n",
       "3        unknown          Hardware,Messaging and Telecommunications   NaN   \n",
       "4          11-50  Content and Publishing,Design,Media and Entert...   NaN   \n",
       "\n",
       "                           NAME  \\\n",
       "0                      Infinity   \n",
       "1                SkyView Agency   \n",
       "2                 Muio Creative   \n",
       "3  Viti Talk Telecommunications   \n",
       "4         Membership Cards Only   \n",
       "\n",
       "                                         LINKEDIN COUNTRY  \\\n",
       "0                                             NaN     USA   \n",
       "1             linkedin.com/company/skyview-agency     USA   \n",
       "2                                             NaN     JPN   \n",
       "3                                             NaN     FJI   \n",
       "4  linkedin.com/company/membership-cards-only-llc     AUT   \n",
       "\n",
       "                                          CRUNCHBASE  \n",
       "0          crunchbase.com/organization/infinity-2052  \n",
       "1         crunchbase.com/organization/skyview-agency  \n",
       "2          crunchbase.com/organization/muio-creative  \n",
       "3  crunchbase.com/organization/viti-talk-telecomm...  \n",
       "4  crunchbase.com/organization/membership-cards-only  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "node_id": "gZPu0YZYWcdJY78Iotncho",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "3vfjiwGNmsql5qzwYMbs5i"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_organizations_df_website = np.array_split(crunchbase_organizations_df[crunchbase_organizations_df['DOMAIN'].isna() == False][['DOMAIN']].rename(columns={'DOMAIN': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_organizations_df_website:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"DomainURL\"), \"URL\"),\n",
    "    )\n",
    "\n",
    "crunchbase_organizations_df_linkedin = np.array_split(crunchbase_organizations_df[crunchbase_organizations_df['LINKEDIN'].isna() == False][['LINKEDIN']].rename(columns={'LINKEDIN': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_organizations_df_linkedin:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"LinkedInURL\"), \"URL\"),\n",
    "    )\n",
    "    \n",
    "crunchbase_organizations_df_twitter = np.array_split(crunchbase_organizations_df[crunchbase_organizations_df['TWITTER'].isna() == False][['TWITTER']].rename(columns={'TWITTER': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_organizations_df_twitter:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"TwitterURL\"), \"URL\"),\n",
    "    )\n",
    "\n",
    "crunchbase_organizations_df_facebook =  np.array_split(crunchbase_organizations_df[crunchbase_organizations_df['FACEBOOK'].isna() == False][['FACEBOOK']].rename(columns={'FACEBOOK': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_organizations_df_facebook:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"FacebookURL\"), \"URL\"),\n",
    "    )\n",
    "\n",
    "crunchbase_organizations_df_crunchbase =  np.array_split(crunchbase_organizations_df[crunchbase_organizations_df['CRUNCHBASE'].isna() == False][['CRUNCHBASE']].rename(columns={'CRUNCHBASE': 'URL'}).to_dict('records'), BATCHES)\n",
    "for chunk_df in crunchbase_organizations_df_crunchbase:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"URLIdentifier\", \"CrunchbaseURL\"), \"URL\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "1J6egvYRmRtF5rHZhq0Mal",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "5SsLLTL1wLgxPSuFyAHATX"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "crunchbase_organizations = np.array_split([{k:v for k, v in x.items() if v == v} for x in crunchbase_organizations_df.to_dict('records')], BATCHES)\n",
    "for chunk_df in crunchbase_organizations:\n",
    "    merge_nodes(\n",
    "        graph.auto(),\n",
    "        chunk_df,\n",
    "        ((\"Company\", \"CrunchbaseCompany\"), \"SOURCE_ID\"),\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "36oVg7pVnU6PcXvGGqn7eC",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "9mS4juf3oYJAosGOqcxqEf"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for identifier in ['DOMAIN', 'LINKEDIN', 'TWITTER', 'FACEBOOK', 'CRUNCHBASE']:\n",
    "    crunchbase_identifier_relationships = crunchbase_organizations_df.loc[crunchbase_organizations_df[identifier] != np.nan][['SOURCE_ID', identifier]]\n",
    "    crunchbase_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(crunchbase_identifier_relationships))\n",
    "\n",
    "    df_list = np.array_split(crunchbase_identifier_relationships, BATCHES)\n",
    "    for chunk_df in df_list:\n",
    "        merge_relationships(\n",
    "            graph.auto(),\n",
    "            chunk_df.values.tolist(),\n",
    "            merge_key=\"LINKED_TO\",\n",
    "            start_node_key=(\"Company\", \"SOURCE_ID\"),\n",
    "            end_node_key=(\"URLIdentifier\", \"URL\"),\n",
    "            keys=[\"WEIGHT\"],\n",
    "        )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "31A3YQMeYeMhyq4ysTiEj2",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "364F1bZv5mgyLi57s8ZwrR"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Relationship creation for previous employment\n",
    "sourcescrub_prev_p2c_df_filtered = sourcescrub_prev_p2c_df.loc[sourcescrub_prev_p2c_df['LINKEDIN'] != np.nan]\n",
    "df_list = np.array_split(sourcescrub_prev_p2c_df_filtered[['PERSON_ID', 'COMPANY_ID']], BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"PREVIOUST_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )\n",
    "\n",
    "# Relationship creation for current employment\n",
    "sourcescrub_curr_p2c_df_filtered = sourcescrub_curr_p2c_df.loc[sourcescrub_curr_p2c_df['LINKEDIN'] != np.nan]\n",
    "df_list = np.array_split(sourcescrub_curr_p2c_df_filtered[['PERSON_ID', 'COMPANY_ID']], BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"CURRENT_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )\n",
    "\n",
    "# Relationship creation for LinkedIn URLs\n",
    "sourcescrub_identifier_relationships = sourcescrub_curr_p2c_df_filtered[['SOURCE_ID', 'LINKEDIN']]\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"LINKED_TO\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "        end_node_key=((\"URLIdentifier\", \"LinkedInURL\"), \"LINKEDIN\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "node_id": "1ME0E6tPMJSfmdCJHuxiJr",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Creating Relationships\n",
    "# Creating relationships between SourceScrub persons and their LinkedIn URLs\n",
    "sourcescrub_identifier_relationships = sourcescrub_persons_df[sourcescrub_persons_df['LINKEDIN'].notna()][['SOURCE_ID', 'LINKEDIN']].copy()\n",
    "sourcescrub_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_identifier_relationships))\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"LINKED_TO\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "        end_node_key=((\"URLIdentifier\", \"LinkedInURL\"), \"LINKEDIN\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )\n",
    "\n",
    ""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Creating Relationships\n",
    "# Creating relationships between SourceScrub persons and their LinkedIn URLs\n",
    "sourcescrub_identifier_relationships = sourcescrub_persons_df[sourcescrub_persons_df['LINKEDIN'].notna()][['SOURCE_ID', 'LINKEDIN']].copy()\n",
    "sourcescrub_identifier_relationships.insert(1, 'WEIGHT', [[0.5]] * len(sourcescrub_identifier_relationships))\n",
    "df_list = np.array_split(sourcescrub_identifier_relationships, BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"LINKED_TO\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"SOURCE_ID\"),\n",
    "        end_node_key=((\"URLIdentifier\", \"LinkedInURL\"), \"LINKEDIN\"),\n",
    "        keys=[\"WEIGHT\"]\n",
    "    )\n",
    "\n",
    "# Step 5: Mapping Identifiers\n",
    "# Preparing relationships between persons and companies\n",
    "sourcescrub_p2c_df = cursor.execute('SELECT PERSONID ,COMPANYID, STARTDATE, ENDDATE FROM L1.SOURCESCRUB_PERSONTOCOMPANY').fetch_pandas_all()\n",
    "sourcescrub_p2c_df.rename(columns={'PERSONID': 'PERSON_ID', 'COMPANYID': 'COMPANY_ID', 'STARTDATE': 'START_DATE', 'ENDDATE': 'END_DATE'}, inplace=True)\n",
    "\n",
    "# Creating relationships for previous employment\n",
    "sourcescrub_prev_p2c_df = sourcescrub_p2c_df[sourcescrub_p2c_df.END_DATE.notna()]\n",
    "df_list = np.array_split(sourcescrub_prev_p2c_df[['PERSON_ID', 'COMPANY_ID']], BATCHES)\n",
    "\n",
    "for chunk_df in df_list:\n",
    "    merge_relationships(\n",
    "        graph.auto(),\n",
    "        chunk_df.values.tolist(),\n",
    "        merge_key=\"PREVIOUS_EMPLOYMENT\",\n",
    "        start_node_key=((\"Person\", \"SourcescrubPerson\"), \"PERSON_ID\"),\n",
    "        end_node_key=((\"Company\", \"SourcescrubCompany\"), \"COMPANY_ID\"),\n",
    "        keys=[]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  },
  "datalore": {
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": [],
   "report_row_ids": [
    "LXlZ1NeQDTK0mx93kQDFEG",
    "sx94cb9xUkhcte19ETSAF4",
    "biDlE0bNXIAuEpUELHXGcJ",
    "CChejMMVamyPr16weP6Oq8",
    "8NwKibJn7nAgQMJUzPCbfS",
    "V1d1lRZPImxSKcD9c2O7nc",
    "nzcr9gq4IH3vZ3jWILMrhM",
    "dtnnIlhFavqQZ9AZmowGCD",
    "KXwIvq45IBBRjVUzjS90Bf",
    "o9OIqLPjso8cmf8zVvegva",
    "Gz8cMbVeF4VFv0RQeSSyE8",
    "KlX1PJTSfq7XP6w5QMQc2D",
    "pjbAuBPpBnGmkziRTPPw27",
    "DjRzLlMy9pqa2GL2R4gMGc",
    "VaAuUvdiPt8RT4JH90wHZA",
    "G8qFgE0TH9oNspv36ObIQX",
    "JHMwNAZEzhBPFa7tc3Lens",
    "qTFa18DszyzNvKBnuREhWt",
    "TAhZf2zUnjdwAKicpENciY",
    "OOHXTgSz1UlUU9YzWBQ2h2",
    "PWPAyAf0WBj04pYtSvPxlF",
    "gCeoNr1sJ0DWPaeJdGL7yc",
    "JmF6iqQ5EyxPP6kJcMozlX",
    "9p8A8l8gzQp7m9HU5HPTBl",
    "9N0q5HAoJAjVy47BRWTD57",
    "PUguPOEwdeov3ooqLu25mw",
    "dt6akrXDGJ7FxI1RaHZiWY",
    "ayTVqtsljnOr9Qk7YoUy0k",
    "nOkY0tmaNT8ffM9sIHF1M8",
    "vUqNDaEKcHsgJN1wJHZgTX",
    "2k3SZ8K4Via8xnhoMErxGt",
    "IjklOPqGyju9jqSZkjAHnJ",
    "3vfjiwGNmsql5qzwYMbs5i",
    "5SsLLTL1wLgxPSuFyAHATX",
    "9mS4juf3oYJAosGOqcxqEf",
    "364F1bZv5mgyLi57s8ZwrR"
   ],
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
